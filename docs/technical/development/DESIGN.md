# 设计方案文档

## 1. 数据采集方案

### App Store
- **优先使用**: `itunes-app-scraper` (开源工具)
- **如果不够用**: 自己实现，使用App Store RSS feed或网页爬虫
- **数据字段**: App ID、名称、分类、评分、评论数、价格、更新日期等

### Product Hunt
- **现状**: 需要自己实现（动态页面，可能需要Selenium）
- **替代方案**: 
  - 查找是否有官方API
  - 使用第三方服务（如Crawlbase）
  - 手动采集（初期）

### Google Play
- **暂时不启用**（后续扩展）

## 2. 机会评分模型

### 评分维度（权重可调）

1. **市场规模 (30%)**
   - 基于评论数/下载量
   - 评论数越多 = 市场越大

2. **竞争程度 (25%)**
   - 评分在4.0-4.5之间 = 竞争不激烈 = 有机会
   - 评分太高 = 竞争激烈
   - 评分太低 = 产品太差

3. **用户满意度 (20%)**
   - 评分4.0-4.5 = 有改进空间 = 机会
   - 可以做得更好

4. **增长趋势 (15%)**
   - 基于更新频率、新评论等
   - 暂时简化处理，后续优化

5. **变现潜力 (10%)**
   - 基于价格、内购等
   - 有价格 = 有变现潜力

### 筛选阈值（可调）

- 最低机会分数: 0.6
- 最少评论数: 10
- 最多竞品数: 20（后续实现）

## 3. 数据流程

```
数据采集 → 原始数据存储 → 数据分析 → 机会评分 → 结果输出
   ↓            ↓              ↓           ↓          ↓
scrapers/   data/raw/    analyzers/   models/   data/processed/
```

## 4. 持续优化方向

### 数据采集
- [ ] 添加更多数据源（Google Play、Chrome Web Store等）
- [ ] 优化爬虫效率（并发、缓存）
- [ ] 添加数据验证和清洗

### 评分模型
- [ ] 根据实际数据调整权重
- [ ] 添加更多维度（如评论情感分析）
- [ ] 机器学习优化（后续）

### 筛选标准
- [ ] 根据试错结果调整阈值
- [ ] 添加行业/分类特定标准
- [ ] 动态调整（基于历史数据）

## 5. 快速试错流程

1. **周一**: 运行数据采集和分析
2. **周二**: 选择Top 3机会，快速研究
3. **周三-周五**: 开发MVP（1-2周完成）
4. **周末**: 上线，收集反馈
5. **下周**: 分析数据，决定继续 or 放弃

## 6. 技术栈

- **数据采集**: Python + requests/BeautifulSoup/Selenium
- **数据分析**: pandas + numpy
- **数据存储**: SQLite + JSON
- **可视化**: matplotlib/seaborn（后续）

## 7. 注意事项

1. **遵守爬虫规范**: 添加延迟，避免被封
2. **数据合法性**: 仅用于个人研究，不商业使用
3. **持续优化**: 根据实际使用情况调整
